{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in your name, student id number and email address\n",
    "#### name:\n",
    "#### student id:\n",
    "#### email:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis and knowledge discovery - Exercise 3: Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the template for the third exercise. The purpose of this exercise is to familiarize yourself with the basics of unsupervised learning by using the agglomerative hierarchical clustering and k-means clustering algorithms to find patterns.\n",
    "\n",
    "The data set utilised in this exercise is a simplified and downsampled version of a knowledge discovery and data mining competition data set. The data will be available on the course's Moodle page. For those who are interested, the original data can be found at https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html. However, please make sure to **use the version on Moodle** as `ex3_network_data.csv`. The data is described below.\n",
    "\n",
    "The data set contains samples of network activity simulated in a military network environment. There are different types of malicious activity, and also activity that is considered normal. It is **not necessary** to understand the details of the data set in order to complete the exercise.\n",
    "\n",
    "In addition to normal activity, there are 3 types of malicious activity - denial of service, unauthorized remote login, and network probing (e.g. port scanning) - simulated in a military network environment. There are 500 samples of each class. There are 6 numeric features, described below:\n",
    "\n",
    "`src_bytes`: number of bytes from source to destination\\\n",
    "`dst_bytes`: number of bytes from destination to source\\\n",
    "`duration`: length of connection (seconds)\\\n",
    "`count`: number of connections to the same host as the current connection in the past two seconds\\\n",
    "`serror_rate`: percentage of connections that have SYN errors\\\n",
    "`rerror_rate`: percentage of connections that have REJ errors\n",
    "\n",
    "In real applications, visualizing and cleaning the data are important steps. However, in this exercise you can treat the data as given, and focus on the unsupervised methods.\n",
    "\n",
    "Please consider the following things when returning your notebook:\n",
    "\n",
    " - As in the two previous exercises, the grading scale is failed/passed/passed with honors.\n",
    " \n",
    " - For a passing grade each part of the exercise, except for the BONUS, must be completed, and all questions should be answered. Some mistakes are allowed as long as you clearly attempt to solve all the exercises.\n",
    " \n",
    " - For doing both the exercise and the optional bonus task sufficiently well, you will be awarded one bonus point for the exam.\n",
    " \n",
    " - All the cells in the finished notebook should run without crashing. Please delete unnecessary cells. As a good rule of thumb, use \"Restart and run all\" on the finished notebook to make sure it runs without errors and produces the expected output.\n",
    "\n",
    " - Remember to comment your code to explain how it works and what you intend for it to do.\n",
    " \n",
    " - Answer the questions asked in the assignments in Markdown cells.\n",
    " \n",
    " - If you are having problems with this exercise, try an online search first, but don't just copy-paste any code you find. See exercise guidelines in the Moodle page of this course. If you can't find a solution to your problem, ask for advice in the course discussion forum on Moodle or contact oskari.s.heikkinen@utu.fi.\n",
    " \n",
    " - If/when you look things up during this exercise, please cite your sources (e.g. a link to a web page). It's better to cite too much than too little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library imports, Jupyter Notebook settings etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below libraries are sufficient to complete the exercise. You can import additional functionality here if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "- Download the exercise 3 data on the Moodle page of this course.\n",
    "- Read the data into a Pandas dataframe.\n",
    "- Display a few rows and some basic information to make sure the data was loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preprocess and visualize the data\n",
    "\n",
    " - Perform z-score standardization on the features to ensure that all features have the same scale.\n",
    " \n",
    " - Project the data to two dimensions by using principal component analysis (PCA) and visualize the resulting two-dimensional data in a scatter plot. Don't color the scatter plot yet.\n",
    " \n",
    " - Does it look like there are clear clusters? Don't worry if they're hard to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because clustering is an unsupervised learning method, the `class` column is completely unnecessary for most of these tasks. You will only need the `class` column in **Part 4**, where it's used to compute a performance metric and to visually compare clustering results to the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: Agglomerative hierarchical clustering\n",
    " \n",
    " - Cluster the data into 4 clusters using agglomerative hierarchical clustering. Try different values for the \"linkage\" parameter.\n",
    " \n",
    " - Use the z-score standardized 6-dimensional data for clustering - not the principal components!\n",
    " \n",
    " - What is the significance of the linkage criterion in a hierarchical clustering algorithm?\n",
    " \n",
    " - Evaluate the clustering performance for each linkage criterion using a metric called \"silhouette score\".\n",
    " \n",
    " - What does silhouette score quantify and how is it computed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: Dendrograms\n",
    "\n",
    " - Plot dendrograms to visualize the merging processes.\n",
    " - For this you will need a linkage matrix. Hint: while you can extract one from a fitted AgglomerativeClustering object, it is much easier to use the scipy implementation (scipy.cluster.hierarchy.linkage).\n",
    " - Compute the linkage matrix using both `average` and `complete` linkage, and plot the dendrograms using scipy.cluster.hierarchy.dendrogram).\n",
    " - Truncate the dendrogram so that three levels of the dendrogram tree are visible for better readability.\n",
    " - How do you interpret the dendrograms? How do they differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: _k_-means clustering\n",
    "\n",
    " - Perform _k_-means clustering on the data. Use 4 clusters.\n",
    " - Evaluate the clustering performance using silhouette score.\n",
    " - Experiment with some other numbers of clusters. Does the data fit better into a different number of clusters according to silhouette score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rand score briefly described\n",
    "\n",
    "Rand score is a measure of similarity between two partitions of a set of elements - in this case true classes and clusters found by the clustering algorithm - and it is one of the most frequently used performance metrics for clustering. It is computed by considering each pair of elements in the dataset and counting pairs of elements as follows:\n",
    " \n",
    "         a: number of pairs such that the elements are in the same class and in the same cluster\n",
    "         b: number of pairs such that the elements are in different classes and in different clusters\n",
    "         c: number of pairs such that the elements are in the same class but in different clusters\n",
    "         d: number of pairs such that the elements are in different classes but in the same cluster\n",
    "     \n",
    "     Given a, b, c, d, the formula for rand index is:\n",
    "     \n",
    "         rand_index = (a+b)/(a+b+c+d).\n",
    "     \n",
    "\"Adjusted Rand index\" is corrected for chance by using maximum and expected values of Rand index.\n",
    "\n",
    "        adj_rand_index = (rand_index - expected_rand_index) / (max_rand_index - expected_rand_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 4a: Compare the clusters with the true labels (hierarchical clustering)\n",
    " \n",
    " - Cluster the data into 4 clusters using agglomerative hierarchical clustering.\n",
    " - Choose the linkage criterion that had the best silhouette score performance in Part 2a.\n",
    " - Visualize the data again using PCA, this time coloring the scatter plot based on the true class labels. Visually compare the two scatter plots: how well do the clusters found by the clustering algorithm match the true classes? Place the two scatter plots so that they can easily be compared (e.g. in subplots next to each other in the same figure).\n",
    " - For an objective evaluation of the clustering, compute the adjusted Rand score (use the scikit-learn implementation) using the true labels and the labels predicted by clustering algorithm. How do you interpret the result?\n",
    " - If the results seem unimpressive, don't get discouraged - clustering \"real life\" data sets to match classes is a difficult task, and a low Rand score does not necessarily mean that you have made a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4b: Compare the clusters with true labels (_k_-means clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Repeat the above steps, but this time using _k_-means clustering instead of hierarchical clustering.\n",
    " - Which performs better according to the adjusted Rand score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 (optional BONUS task): Clustering unlabeled data\n",
    "\n",
    "In this task, you are working with data where the classes are not available, given as `ex3_seeds_data_BONUS.csv` on Moodle. [The original data set](https://archive.ics.uci.edu/ml/datasets/seeds) is available for for those who are interested, but **use the slightly modified data on Moodle** instead.\n",
    "\n",
    "In general this is a very challenging and open-ended type of task that requires in-depth domain knowledge for meaningful results. Note, however, that in this exercise you are **not required** to research the domain in question (e.g. properties of different varieties of wheat). You might need to search for more information related to clustering in order to complete this exercise.\n",
    "\n",
    "Some of the questions are open-ended and have no correct answer. It's enough to clearly show that you thought about the questions.\n",
    "\n",
    " - As in Part 1, z-score standardize the data, project it to 2 dimensions using PCA and visualize the result in a scatter plot.\n",
    " - Does the scatter plot look like the data might have a clustered structure? How many clusters do you see?\n",
    " - Decide, based on what you've learned about silhouette score and Rand score, which performance metric you should use in this task. Justify your choice.\n",
    " - Get an objective evaluation of how many clusters the data most likely has by using your chosen performance metric. Try both _k_-means clustering and agglomerative hierarchical clustering with different linkage criterions and see which performs best.\n",
    " - Visualize (with color) the best-performing result in the PCA scatter plot you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
